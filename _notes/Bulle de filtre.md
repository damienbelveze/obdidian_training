---
title: Bulle de filtre
subtitle:
author: Damien Belvèze
date: 20210301
link_citations: true
tags: [désinformation]
aliases: [bulle de filtrage, bulles de filtres, filter bubble, bulle de filtre, filter bubbles, bulle informationnelle, bulles informationnelles]
---

obtenir des informations personnalisées, c'est permettre que le moteur de recherche vous catégorise et vous enferme dans votre catégorie. 

# l'usager est un "profilé"

Profil est le maître-mot du web depuis 2010. 
cf. Olivier Le Deuff ([[@LeDeuffRipostedigitalePour2021]])

> L’usager est donc surtout devenu un profilé qu’on cherche à suivre pour mieux le comprendre, pour améliorer les systèmes d’information et bien entendu afin de pouvoir également mieux monétiser les systèmes en vue d’optimiser les logiques publicitaires

# La croyance en la [[neutralité de la technique]] s'applique aussi aux moteurs de recherche

La méconnaissance de la bulle de filtre peut être vue comme un avatar de la croyance du public dans la neutralité des moteurs de recherche
> The widespread trust put into search engines can be viewed as a manifestation of the public's belief in the neutrality of technology and its unawareness of the social values that are part and parcel of any piece of technology's design 
[[@TewellResistantReadingInformation2016]]

# Bulles de filtre et polarisation

Eli Pariser en 2011[[@PariserconferenceTEDxfilter2011]] a montré comment les services web, à commencer par les moteurs de recherche comme Google servaient des résultats différents en fonction des profils des utilisateurs basés sur leur comportement en ligne et leurs préférences. 
Les bulles de filtre condamnent les citoyens à rester aveugles aux opinions et aux goûts qui ne sont pas les leurs, renforçant à la fois leurs convictions dans ces optinions et les enfermant dans leurs choix. Cela produit sur le plan culturel une routinisation des pratiques et sur le plan politique une [[polarisation]] des débats et prises de position. 



# Nuancer la portée de la bulle de filtre suscitée par les moteurs de recherche et les réseaux sociaux

## la bulle de filtre : un effet de l'[[isolement collectif]]

Une étude d'octobre 2022, parue sur Nature, conteste la pertinence de la chambre d'écho ou bulle de filtre pour expliquer le phénomène de polarisation et de [[guerre culturelle|guerres culturelles]] que connaissent les USA et de nombreux pays occidentaux aujourd'hui. 
Selon cette étude, ce n'est pas l'isolement dans une sphère homogène sur le plan idéologique -favorisée par les réseaux sociaux- qui serait à l'origine de ce phénomène, mais au contraire la multiplication d'interactions avec des personnes qui pensent différemment sur un point et avec lesquelles nous avons l'impression de ne rien partager du tout (alors que localement, si nous ne votons pas pour le même candidat, nous avons peut-être la même religion, fréquentons les mêmes stades et supportons les mêmes équipes)[[@tornbergHowDigitalMedia2022]] : 

> Combining insights from these literatures, the paper thus presents a computational model that isolates an emergent mechanism through which digital media may drive partisan sorting. The suggested mechanism essentially turns the echo chamber on its head: it is not that isolation drives divergence of opinions but that the diverse and nonlocal interactions of digital media drive plural conflicts to align along partisan lines. By connecting individuals outside their local networks, digital media drive a global alignment of conflicts by effacing the counterbalancing effects of local cultures. The model thus suggests that digital media can intensify affective polarization by contributing to a runaway process in which more and more issues become drawn into a single growing social and cultural divide, in turn driving a breakdown of social cohesion.

## Ne pas négliger l'importance des sélections opérées par l'usager lui-même

Dans un article daté de 2015, des chercheurs ont montré toutefois que ce n'était pas tant les [[algorithme|algorithmes]] des réseaux sociaux qui filtraient de manière complètement invisibles les informations en fonction du profil de l'utilisateur, mais plutôt l'utilisateur lui-même en sélectionnant des amis par affinités politiques qui assurait ce filtrage des opinions adverses[[@BakshyExposureideologicallydiverse2015]]. 

il est important de bien distinguer la sélection opérée par l'utilisateur lui-même dans le choix de ses sources d'information (self-selected personalisation) et la personnalisation des résultats provoquée par l'[[algorithme]] du réseau social ou du moteur de recherche.

Dominique Cardon rappelle que même dans les médias sociaux, la sélection contrôlée par les usagers jouent un grand rôle dans la consommation des médias : sur Facebook, nous choisissons de suivre des amis qui globalement pensent à peu près comme nous[[@cardonQuoiReventAlgorithmes2015]]. 

L'extension Horus pour navigateur lancée par l'ISPIF-CNRS (David Chavalarias) a pour but de mesurer l'effectivité des sélections opérées par les outils à l'insu de l'usager sur la base de ses préférences, afin de mieux déterminer quelle est la part prise par ces [[algorithmes]] dans la construction d'une bulle de filtrage. 

## Les réseaux sociaux favorisent une plus grande exposition à une diversité de points de vue, ce qui n'est pas contradictoire avec une plus grande polarisation.

Richard Fletcher a montré également que le fait d'être exposé à de l'information sur les réseaux sociaux nous exposait à une diversité de points de vue plus grande que le fait de sélectionner ses médias et de les lire hors des plateformes sociales. Cependant, cet auteur indique qu'une plus grande diversité de points de vue n'est pas contradictoire avec une plus grande polarisation. Dans son étude portant sur 12 pays, dans 8 pays, les audiences montraient une polarisation plus forte parmi les consommateurs d'informations en ligne que parmi les consommateurs d'information (offline) imprimée. L'exposition au point de vue adverse peut avoir pour effet de se retrancher dans ses convictions antérieures (cf. [[réactance]]) [[@fletcherTruthFilterBubbles2020]]

>[_What we found_](https://journals.sagepub.com/doi/abs/10.1177/1940161219892768) _was that the more people use direct access, the less diverse their news diet was. Not only people are using more sources of news when they get their news on social media. They're using lots of different sources, and the balance between those different sources improves with respect to diversity_

Il n'est pas nécessaire de se laisser enfermer dans un algorithme qui envoie du contenu en fonction de son comportement en ligne pour se fabriquer un monde complètement virtuel et étranger au monde réel. 
Telegram repose uniquement sur de la syndication et renvoie néanmoins à des contenus de désinformation (voir [message de Mike Caufield sur Twitter](https://twitter.com/holden/status/1467565394458075139)



